{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TzGw1WBkFKLtROu_pb73WGe-IwpkQV8V",
      "authorship_tag": "ABX9TyOHXnbJp9wdGZUWQZ8nRLe/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/istiaquehussain/ML-Staging/blob/main/RAG_as_service.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMM8Jt2D9sO5"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf\n",
        "!pip install panda\n",
        "!pip install google.generativeai\n",
        "!pip install pinecone-client\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langchain-pinecone\n",
        "!pip install langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader, CSVLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_pinecone import PineconeVectorStore\n"
      ],
      "metadata": {
        "id": "keeh0gHo99sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RAG:\n",
        "  #util = None\n",
        "  #llm = None\n",
        "  #vector_store = None\n",
        "  #emabdding = None\n",
        "  #extractor = None\n",
        "  #loader = None\n",
        "\n",
        "  def __init__(self,llm,vector_store,extractor,util):\n",
        "    self.util = util\n",
        "    self.llm = llm\n",
        "    self.vector_store = vector_store\n",
        "    self.emabdding = llm.get_emabdding()\n",
        "    self.extractor = extractor\n",
        "    pass\n",
        "  def set_util(self,util):\n",
        "    self.util = util\n",
        "\n",
        "  def get_util(self):\n",
        "    return self.util\n",
        "\n",
        "  def set_llm(self,llm):\n",
        "    self.llm\n",
        "\n",
        "  def get_llm(self):\n",
        "    return self.llm\n",
        "\n",
        "  def set_vector_store(self,vector_store):\n",
        "    self.vector_store = vector_store\n",
        "\n",
        "  def get_vector_store(self):\n",
        "    return self.vector_store\n",
        "\n",
        "  def set_emabdding(self,emabdding):\n",
        "    self.emabdding = emabdding\n",
        "\n",
        "  def get_emabdding(self):\n",
        "    return self.emabdding\n",
        "\n",
        "  def set_extractor(self,extractor):\n",
        "    self.extractor=extractor\n",
        "\n",
        "  def get_extractor(self):\n",
        "    return self.extractor\n",
        "\n",
        "  def set_loader(self,loader):\n",
        "    self.extractor=loader\n",
        "\n",
        "  def get_loader(self):\n",
        "    return self.loader\n",
        "\n",
        "  def create_sanitised_csv(self,csv_file_path_with_name:str,colums_to_return:list,total_row=0,file_name_extn=\"_sanitized\"):\n",
        "    return self.util.sanitise_csv(csv_file_path_with_name,colums_to_return,total_row,file_name_extn)\n",
        "\n",
        "  def extract_csv(self,csv_file_path_with_name:str):\n",
        "    return self.extractor.extract_csv(csv_file_path_with_name)\n",
        "\n",
        "  def extract_pdf(self,pdf_file_path_with_name:str):\n",
        "    return self.extractor.extract_pdf(pdf_file_path_with_name)\n",
        "\n",
        "  def extract_text(self,text_file_path_with_name:str):\n",
        "    return self.extractor.extract_text(text_file_path_with_name)\n",
        "\n",
        "  def insert(self, documents,chunk_size=100):\n",
        "    self.vector_store.insert(documents,chunk_size)\n",
        "\n",
        "  def find(self,query_string,total_docs:int,meta:dict):\n",
        "    retriever_result = self.vector_store.find(query_string,total_docs,meta)\n",
        "    return retriever_result\n",
        "\n",
        "  def query(self,template,retriever_result,query):\n",
        "    return self.llm.query(template,retriever_result,query)\n",
        "\n",
        "  def query_with_docs(self,template_string,docs,query):\n",
        "    return self.llm.query_with_docs(template_string,docs,query)\n",
        "\n",
        "\n",
        "  def load(self,load_request):\n",
        "    load_request=self.util.generate_load_request(load_request)\n",
        "    if(load_request['request_type']==\"csv\"):\n",
        "      self.load_csv(load_request['uri'],load_request['meta'])\n",
        "    elif(load_request['request_type']==\"pdf\"):\n",
        "      self.load_pdf(load_request['uri'],load_request['meta'])\n",
        "\n",
        "  def load_csv(self,csv_file_path_with_name:str,meta:dict):\n",
        "    documents = self.extract_csv(csv_file_path_with_name)\n",
        "\n",
        "    if(meta):\n",
        "      for document in documents:\n",
        "        document.metadata.update(meta)\n",
        "\n",
        "    self.insert(documents)\n",
        "\n",
        "  def load_pdf(self,pef_file_path_with_name:str,meta:dict):\n",
        "    documents = self.extract_pdf(pef_file_path_with_name)\n",
        "    if(meta):\n",
        "      for document in documents:\n",
        "        document.metadata.update(meta)\n",
        "\n",
        "    self.insert(documents)\n",
        "\n",
        "  def generate(self,query_request,should_log=False):\n",
        "     query_request=self.util.generate_query_request(query_request)\n",
        "     if(query_request['query']):\n",
        "        query=query_request['query']\n",
        "        total_docs=\"0\"\n",
        "        template_meta={'type':'all'}\n",
        "        if(query_request['total_records']):\n",
        "          total_docs=str(query_request['total_records'])\n",
        "        total_docs = int(total_docs)\n",
        "        if(query_request['template_type']):\n",
        "          template_type=query_request['template_type']\n",
        "        meta=query_request['meta']\n",
        "        response = self.generate_response(query,total_docs,meta,template_meta,should_log)\n",
        "        return response\n",
        "     else:\n",
        "      return None\n",
        "\n",
        "  def generate_response(self,query,total_docs:int,vector_meta:dict,template_meta:dict,should_log=False):\n",
        "     if(should_log):\n",
        "      print(f\"query->{query},total_docs->{total_docs},vector_meta->{vector_meta},template_meta->{template_meta}\")\n",
        "     docs = self.find(query,total_docs,vector_meta)\n",
        "     if(should_log):\n",
        "      for doc in docs:\n",
        "        print(\"---------------------------------\")\n",
        "        print(f\"doc->{doc.page_content}\")\n",
        "     if(docs and len(docs)>0):\n",
        "        templates=self.llm.get_templates()\n",
        "        if(should_log):\n",
        "          print(f\"templates->{templates}\")\n",
        "        template=templates[template_meta['type']]\n",
        "        if(should_log):\n",
        "          print(f\"template->{template}\")\n",
        "        res = self.query_with_docs(template,docs,query)\n",
        "        if(should_log):\n",
        "          print(f\"res->{res}\")\n",
        "        return res\n",
        "     else:\n",
        "      return None\n"
      ],
      "metadata": {
        "id": "l7bcpjV_-Cd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Util:\n",
        "\n",
        "   def __init__(self):\n",
        "        pass\n",
        "\n",
        "   def sanitise_csv(self,csv_file_path_with_name:str,colums_to_return:list,total_row=0,file_name_extn=\"_sanitized\",)->str:\n",
        "        df=pd.read_csv(csv_file_path_with_name,usecols=colums_to_return)\n",
        "\n",
        "        if(total_row>0):\n",
        "          df=df.iloc[:total_row]\n",
        "\n",
        "        sanitized_df=self.sanitise_csv_custom(df,colums_to_return)\n",
        "        #sanitized_df.to_csv(csv_file_path_with_name,index=False)\n",
        "\n",
        "        directory = os.path.dirname(csv_file_path_with_name)\n",
        "        file_name = os.path.basename(csv_file_path_with_name)\n",
        "\n",
        "        # Split the file name and extension\n",
        "        file_base, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "        # Create the new file name\n",
        "        new_file_name = f\"{file_base}{file_name_extn}{file_extension}\"\n",
        "\n",
        "        # Join the directory and new file name to get the new path\n",
        "        new_path_name = os.path.join(directory, new_file_name)\n",
        "        sanitized_df.to_csv(new_path_name,index=False)\n",
        "        return new_path_name\n",
        "\n",
        "   def sanitise_csv_custom(self,data_frame:pd,colums_to_return:list)->pd:\n",
        "      data_to_sanitised = data_frame.copy(deep=True)\n",
        "\n",
        "      data_sanitised = data_to_sanitised[colums_to_return]\n",
        "      data_sanitised['Resolution'] = data_sanitised['Resolution'].fillna('No resolution comments')\n",
        "      data_sanitised['Customer Satisfaction Rating'] = data_sanitised['Customer Satisfaction Rating'].fillna('No ratings')\n",
        "      data_sanitised.fillna('',inplace=True)\n",
        "\n",
        "      def format_ticket_description(row):\n",
        "        row_content=row['Ticket Description'].replace('{product_purchased}',row['Product Purchased'])\n",
        "        return row_content\n",
        "\n",
        "      data_sanitised[\"Ticket Description Corrected\"] = data_sanitised.apply(format_ticket_description, axis=1)\n",
        "\n",
        "      data_sanitised.drop(['Ticket Description'],axis=1,inplace=True)\n",
        "      data_sanitised.rename(columns={'Ticket Description Corrected':'Ticket Description'},inplace=True)\n",
        "      data_sanitised['Ticket Description'] = data_sanitised['Ticket Description'].str.replace('\\n', ' ', regex=True)\n",
        "      return data_sanitised\n",
        "\n",
        "\n",
        "   def transform_csv_to_vector(self,data:pd)->pd:\n",
        "      data_frame = data.copy(deep=True)\n",
        "      #data_frame['vector_transformed']=data_frame.apply(lambda row:row['vector'].toList,axis=1)\n",
        "      data_frame['vector_transformed']=data_frame.apply(lambda row:json.loads(row['vector']),axis=1)\n",
        "      data_frame.drop(['vector'],axis=1,inplace=True)\n",
        "      data_frame.rename(columns={'vector_transformed':'vector'},inplace=True)\n",
        "      return data_frame[['id','vector','data','meta']]\n",
        "\n",
        "   def export_data_to_csv(self,data:pd,file_path:str,chunk_size:int):\n",
        "      for i in range(0, len(data), chunk_size):\n",
        "        chunk = data.iloc[i:i + chunk_size]\n",
        "        file_name =f'output_chunk_{i // chunk_size + 1}.csv'\n",
        "        chunk.to_csv(file_path+\"/\"+file_name, index=False)\n",
        "   \"\"\" Load and query request format should be\n",
        "\n",
        "   load_request={\n",
        "      \"request_type\":\"csv\",\n",
        "      \"uri\":\"https://static.realpython.com/python-basics-sample-chapters.pdf\",\n",
        "      \"meta\":{\n",
        "          \"doc_type\":\"csv\"\n",
        "          }\n",
        "      }\n",
        "   query_request={\n",
        "    \"query\":\"list issues with xbox\",\n",
        "    \"template_type\":\"csv\",\n",
        "    \"total_records\":4,\n",
        "    \"meta\":{\n",
        "        \"doc_type\":\"csv\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "  \"\"\"\n",
        "   def generate_load_request(self,load_request)->dict:\n",
        "      if load_request.__class__ == dict:\n",
        "        load_request_=json.loads(json.dumps(load_request,indent=4))\n",
        "      else:\n",
        "        load_request_=json.loads(load_request)\n",
        "      request_type=load_request_.get('request_type',None)\n",
        "      uri=load_request_.get('uri',None)\n",
        "      meta = load_request_.get('meta',None)\n",
        "      doc_type = None\n",
        "      if(meta):\n",
        "        doc_type=meta.get('doc_type',None)\n",
        "      return {\"uri\":uri,\"request_type\":request_type,\"meta\":meta,\"doc_type\":doc_type}\n",
        "\n",
        "   def generate_load_request_old(self,load_request)->dict:\n",
        "      if load_request.__class__ == dict:\n",
        "        load_request_=json.loads(json.dumps(load_request,indent=4))\n",
        "      else:\n",
        "        load_request_=json.loads(load_request)\n",
        "      request_type=None\n",
        "      uri=None\n",
        "      meta = None\n",
        "      doc_type = None\n",
        "      if(load_request_['request_type']):\n",
        "        request_type=load_request_['request_type']\n",
        "      if(load_request_['uri']):\n",
        "        uri=load_request_['uri']\n",
        "      if(load_request_['meta']):\n",
        "        meta=load_request_['meta']\n",
        "        if(load_request_['meta']['doc_type']):\n",
        "          doc_type=load_request_['meta']['doc_type']\n",
        "      return {\"uri\":uri,\"request_type\":request_type,\"meta\":meta,\"doc_type\":doc_type}\n",
        "\n",
        "   def generate_query_request(self,query_request)->dict:\n",
        "      if query_request.__class__ == dict:\n",
        "        query_request_=json.loads(json.dumps(query_request,indent=4))\n",
        "      else:\n",
        "        query_request_=json.loads(query_request)\n",
        "      query=query_request_.get('query',None)\n",
        "      total_docs=query_request_.get('total_records',None)\n",
        "      template_type=query_request_.get('template_type',None)\n",
        "      meta = query_request_.get('meta',None)\n",
        "      doc_type = None\n",
        "      if(meta):\n",
        "        doc_type=meta.get('doc_type',None)\n",
        "      return {\"query\":query,\"total_records\":total_docs,\"template_type\":template_type,\"meta\":meta,\"doc_type\":doc_type}\n",
        "\n",
        "\n",
        "\n",
        "   def generate_query_request_old(self,query_request)->dict:\n",
        "      if query_request.__class__ == dict:\n",
        "        query_request_=json.loads(json.dumps(query_request,indent=4))\n",
        "      else:\n",
        "        query_request_=json.loads(query_request)\n",
        "      query=None\n",
        "      template_type=None\n",
        "      meta = None\n",
        "      doc_type = None\n",
        "      total_docs = None\n",
        "      if(query_request_['total_records']):\n",
        "        total_docs=query_request_['total_records']\n",
        "      if(query_request_['query']):\n",
        "        query=query_request_['query']\n",
        "      if(query_request_['template_type']):\n",
        "        template_type=query_request_['template_type']\n",
        "      if(query_request_['meta']):\n",
        "        meta=query_request_['meta']\n",
        "        if(query_request_['meta']['doc_type']):\n",
        "          doc_type=query_request_['meta']['doc_type']\n",
        "      return {\"query\":query,\"total_records\":total_docs,\"template_type\":template_type,\"meta\":meta,\"doc_type\":doc_type}\n",
        "\n",
        "   def get_genai_template(self)->str:\n",
        "    genai_query_template=\"\"\"\n",
        "      summarize below customer ticket system data :\n",
        "\n",
        "      {context}\n",
        "\n",
        "      always include 'Product Purchased','Ticket Description' and 'Customer Satisfaction Rating' in your response.\n",
        "      \"\"\"\n",
        "    genai_query_template = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Answer the question based on the above context: {query}\n",
        "\"\"\"\n",
        "    genai_query_template = \"\"\"You are a data analyst. Given the following data of customer support tickets, provide a detailed summary of the information.Make sure to highlight key points and provide an overall summary of the data.\n",
        "\n",
        "Data:\n",
        "{context}\n",
        "\n",
        "Summary:\"\"\"\n",
        "    return genai_query_template\n",
        "\n",
        "   def get_query_template_for_meta(self,meta_data:map)->str:\n",
        "\n",
        "      qa_template = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Answer the question based on the above context: {query}\n",
        "\"\"\"\n",
        "      summary_template = \"\"\"You are a data analyst. Given the following data of customer support tickets, provide a detailed summary of the information.Make sure to highlight key points and provide an overall summary of the data.\n",
        "\n",
        "Data:\n",
        "{context}\n",
        "\n",
        "Summary:\"\"\"\n",
        "      template_meta ={\"doc\":qa_template,\n",
        "                      \"data\":summary_template}\n",
        "\n",
        "      return template_meta[meta_data['type']]"
      ],
      "metadata": {
        "id": "IZMS_5mWBCfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tL9zpF7j2mBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorStore:\n",
        "  DB_INDEDX_NAME = \"vector-global\"\n",
        "  DB_DIMENTION = 768\n",
        "  DB_METRIX = \"cosine\"\n",
        "  store = None\n",
        "  DB_API_KEY = None\n",
        "  vectordb = None\n",
        "\n",
        "  def __init__(self,db_index_name,db_dimention,db_metrix,api_key):\n",
        "    self.DB_INDEDX_NAME = db_index_name\n",
        "    self.DB_DIMENTION = db_dimention\n",
        "    self.DB_METRIX = db_metrix\n",
        "    self.DB_API_KEY = api_key\n",
        "    pass\n",
        "\n",
        "  def initialize(self,llm_emabdding):\n",
        "      if(self.DB_API_KEY):\n",
        "        self.vectordb = Pinecone(api_key=self.DB_API_KEY)\n",
        "      else:\n",
        "        print(\"please initialize DB_API_KEY\")\n",
        "\n",
        "      if(self.vectordb and self.DB_INDEDX_NAME and self.DB_DIMENTION and self.DB_METRIX):\n",
        "        index_list = self.vectordb.list_indexes()\n",
        "        index_names=[index['name'] for index in index_list]\n",
        "        if self.DB_INDEDX_NAME not in index_names:\n",
        "          self.create_table()\n",
        "        self.store = PineconeVectorStore(index_name=self.DB_INDEDX_NAME, embedding=llm_emabdding,pinecone_api_key=self.DB_API_KEY)\n",
        "      else:\n",
        "          print(\"please initialize  vector db \")\n",
        "\n",
        "  def create_table(self):\n",
        "    if(self.vectordb and self.DB_INDEDX_NAME and self.DB_DIMENTION and self.DB_METRIX):\n",
        "      self.vectordb.create_index(\n",
        "          name=self.DB_INDEDX_NAME,\n",
        "          dimension=self.DB_DIMENTION,\n",
        "          metric=self.DB_METRIX,\n",
        "          spec=ServerlessSpec(\n",
        "              cloud=\"aws\",\n",
        "              region=\"us-east-1\"\n",
        "          )\n",
        "        )\n",
        "    else:\n",
        "        print(f\"please initialize  vectordb->{self.vectordb}, DB_INDEDX_NAME->{self.DB_INDEDX_NAME}, DB_DIMENTION->{self.DB_DIMENTION} , DB_METRIX->{self.DB_METRIX} \")\n",
        "\n",
        "  def drop_table(self):\n",
        "    if(self.vectordb and self.DB_INDEDX_NAME ):\n",
        "      self.vectordb.delete_index(self.DB_INDEDX_NAME)\n",
        "    else:\n",
        "      print(f\"please initialize vectordb->{self.vectordb}, DB_INDEDX_NAME->{self.DB_INDEDX_NAME}\")\n",
        "\n",
        "  def get_store(self):\n",
        "    return self.store\n",
        "\n",
        "  def insert(self, documents,chunk_size=100):\n",
        "    if(self.store):\n",
        "        total_docs=len(documents)\n",
        "        for i in range(0, total_docs, chunk_size):\n",
        "            chunk = documents[i:i + chunk_size]\n",
        "            self.store.add_documents(chunk)\n",
        "    else:\n",
        "        print(f\"please initialize vector_store->{self.vector_store}\")\n",
        "\n",
        "  def find(self,query_string,total_docs:int,meta:dict):\n",
        "      docs = self.store.similarity_search(query=query_string,k=total_docs,filter=meta)\n",
        "      return docs"
      ],
      "metadata": {
        "id": "a6qLOLnaBtKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LLM:\n",
        "  EMBEDING_MODEL_NAME = 'models/embedding-001'\n",
        "  GENAI_MODEL_NAME = 'gemini-pro'\n",
        "  LLM_API_KEY = None\n",
        "  emabdding = None\n",
        "  genai = None\n",
        "  templates = None\n",
        "\n",
        "  def __init__ (self,embadding_model_name,genai_model_name,llm_api_key,templates_json):\n",
        "    self.EMBEDING_MODEL_NAME = embadding_model_name\n",
        "    self.GENAI_MODEL_NAME = genai_model_name\n",
        "    self.LLM_API_KEY = llm_api_key\n",
        "    self.templates = templates_json\n",
        "    pass\n",
        "\n",
        "  def get_templates(self):\n",
        "    return self.templates\n",
        "\n",
        "\n",
        "  def initialize(self):\n",
        "    if(self.LLM_API_KEY):\n",
        "      self.emabdding = GoogleGenerativeAIEmbeddings(google_api_key=self.LLM_API_KEY,model=self.EMBEDING_MODEL_NAME)\n",
        "      self.genai = ChatGoogleGenerativeAI(google_api_key=self.LLM_API_KEY,model=self.GENAI_MODEL_NAME)\n",
        "    else:\n",
        "      print(\"please initialize LLM_API_KEY\")\n",
        "\n",
        "  def get_genai(self):\n",
        "    return self.genai\n",
        "\n",
        "  def get_emabdding(self):\n",
        "    return self.emabdding\n",
        "\n",
        "  def query(self,template,retriever_result,query):\n",
        "    prompt = PromptTemplate.from_template(template)\n",
        "    combine_docs_chain = create_stuff_documents_chain(self.genai, prompt)\n",
        "    combine_docs_chain.invoke\n",
        "    return combine_docs_chain.invoke({\"context\": retriever_result,\"input\":query})\n",
        "\n",
        "  def query_with_docs(self,template_string,docs,query):\n",
        "    append = lambda x: x + \"\\n\"\n",
        "    contexts = [append(doc.page_content) for doc in docs]\n",
        "    prompt_template = PromptTemplate(input_variables=[\"context\", \"input\"],template=template_string)\n",
        "    input_data = {\"context\": contexts,\"input\": query}\n",
        "    prompt = prompt_template.format_prompt(**input_data)\n",
        "    response = self.genai.invoke(prompt)\n",
        "    return response"
      ],
      "metadata": {
        "id": "2912bbBtGzDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Extractor:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def extract_csv(self,csv_file_path_with_name:str):\n",
        "      loader = CSVLoader(csv_file_path_with_name)\n",
        "      documents = loader.load()\n",
        "      return documents\n",
        "\n",
        "    def extract_pdf(self,pdf_file_path_with_name:str):\n",
        "      loader = PyPDFLoader(pdf_file_path_with_name)\n",
        "      text_splitter = CharacterTextSplitter(\n",
        "          separator=\".\",\n",
        "          chunk_size=800,\n",
        "          chunk_overlap=80,\n",
        "          length_function=len,\n",
        "          is_separator_regex=False,\n",
        "      )\n",
        "      documents = loader.load()\n",
        "      documents = text_splitter.split_documents(documents)\n",
        "      return documents\n",
        "\n",
        "    def extract_text(self,text_file_path_with_name:str):\n",
        "      loader = TextLoader(text_file_path_with_name)\n",
        "      text_splitter = CharacterTextSplitter(\n",
        "          separator=\".\",\n",
        "          chunk_size=250,\n",
        "          chunk_overlap=50,\n",
        "          length_function=len,\n",
        "          is_separator_regex=False,\n",
        "      )\n",
        "      documents = loader.load()\n",
        "      documents = text_splitter.split_documents(documents)\n",
        "      return documents"
      ],
      "metadata": {
        "id": "Mr1pyYbh6pWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Template:\n",
        "  qa_template = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Answer the question based on the above context: {input}\n",
        "\"\"\"\n",
        "  summary_template = \"\"\"You are a data analyst. Given the following data of customer support tickets, provide a detailed summary of the information.Make sure to highlight key points and provide an overall summary of the data.\n",
        "\n",
        "Data:\n",
        "{input}\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "  any_template = \"\"\"\n",
        "You are a helpful AI assistant.\n",
        "Answer based on the context provided.\n",
        "context: {context}\n",
        "input: {input}\n",
        "answer:\n",
        "\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  template_meta ={\"doc\":qa_template,\n",
        "                  \"data\":summary_template,\n",
        "                  \"all\":any_template}\n",
        "  def get(self)->str:\n",
        "    return self.template_meta\n",
        "\n",
        "  def get_query_template_for_meta(self,meta_data:map)->str:\n",
        "    return self.template_meta[meta_data['type']]\n"
      ],
      "metadata": {
        "id": "-YtQiLWJQt1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Main:\n",
        "  \"\"\"chat_model=\"gemini-pro\"\n",
        "  embading_model=\"models/embedding-001\"\n",
        "  vector_db_index_name=\"cs-tickets\"\n",
        "  vector_db_dimension=768\n",
        "  vector_db_metrix=\"cosine\"\n",
        "  API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "  vectordb_API_KEY=userdata.get('PINE_CONE_API_KEY')\"\"\"\n",
        "\n",
        "  def initialize(self,chat_model,embading_model,vector_db_index_name,vector_db_dimension,vector_db_metrix,API_KEY,vectordb_API_KEY)->RAG:\n",
        "    \"\"\"chat_model=chat_model\n",
        "    embading_model=embading_model\n",
        "    vector_db_index_name=vector_db_index_name\n",
        "    vector_db_dimension=vector_db_dimension\n",
        "    vector_db_metrix=vector_db_metrix\n",
        "    API_KEY=API_KEY\n",
        "    vectordb_API_KEY=vectordb_API_KEY\"\"\"\n",
        "    llm=LLM(embading_model,chat_model,API_KEY,template.get())\n",
        "    llm.initialize()\n",
        "    vector_store=VectorStore(vector_db_index_name,vector_db_dimension,vector_db_metrix,vectordb_API_KEY)\n",
        "    vector_store.initialize(llm.get_emabdding())\n",
        "    extractor=Extractor()\n",
        "    util=Util()\n",
        "    rag=RAG(llm,vector_store,extractor,util)\n",
        "    self.rag= rag\n",
        "\n",
        "  def delele_db(self):\n",
        "    self.rag.vector_store.drop_table()\n",
        "\n",
        "  def load_content(self,load_request):\n",
        "    self.rag.load(load_request)\n",
        "\n",
        "  def generate_content(self,query_request,should_log=False):\n",
        "    response=self.rag.generate(query_request,should_log)\n",
        "    return response"
      ],
      "metadata": {
        "id": "zn1NMG9o5Dsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model=\"gemini-pro\"\n",
        "embading_model=\"models/embedding-001\"\n",
        "vector_db_index_name=\"cs-tickets\"\n",
        "vector_db_dimension=768\n",
        "vector_db_metrix=\"cosine\"\n",
        "API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "vectordb_API_KEY=userdata.get('PINE_CONE_API_KEY')"
      ],
      "metadata": {
        "id": "7gQ9PzTY9Y_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path_with_name = '/content/drive/MyDrive/datasets/customer_support_tickets.csv'\n",
        "colums_to_return = ['Ticket ID',\n",
        " 'Customer Name',\n",
        " 'Customer Email',\n",
        " 'Customer Age',\n",
        " 'Customer Gender',\n",
        " 'Product Purchased',\n",
        " 'Date of Purchase',\n",
        " 'Ticket Type',\n",
        " 'Ticket Subject',\n",
        " 'Ticket Description',\n",
        " 'Ticket Status',\n",
        " 'Resolution',\n",
        " 'Ticket Priority',\n",
        " 'Ticket Channel',\n",
        " 'Customer Satisfaction Rating']"
      ],
      "metadata": {
        "id": "R-35ihkV-E-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZxbAEICr-EF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main=Main()\n",
        "main.initialize(chat_model,embading_model,vector_db_index_name,vector_db_dimension,vector_db_metrix,API_KEY,vectordb_API_KEY)\n"
      ],
      "metadata": {
        "id": "jmBL_2BK8rqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main.rag.vector_store.drop_table()"
      ],
      "metadata": {
        "id": "AmjQS7NV9wLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saniticzed_csv_path_with_name=main.rag.create_sanitised_csv(csv_file_path_with_name,colums_to_return,550)"
      ],
      "metadata": {
        "id": "Gz6WlPJi-BD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_request={\n",
        "      \"request_type\":\"csv\",\n",
        "      \"uri\":saniticzed_csv_path_with_name,\n",
        "      \"meta\":{\n",
        "          \"doc_type\":\"csv\",\n",
        "          \"doc_name\":\"customer_support_tickets\"\n",
        "          }\n",
        "      }\n",
        "#main.load_content(load_request)"
      ],
      "metadata": {
        "id": "MhwYb9wA-qDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"List related to xbox\"\n",
        "template_meta={\n",
        "    'type':'all'\n",
        "}\n",
        "\n",
        "query_request={\n",
        "    \"query\":\"list issues with playsyation\",\n",
        "    \"template_type\":\"csv\",\n",
        "    \"total_records\":1,\n",
        "    \"meta\":{\n",
        "        \"doc_type\":\"csv\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "query_request={\n",
        "    \"query\":\"list issues with playsyation\",\n",
        "    \"total_records\":4,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "SNAz3kVc-bnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resonse=main.generate_content(query_request)\n",
        "print(resonse.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3CGL3T99sHc",
        "outputId": "e3699789-6e59-401c-f29b-9ba7a8524f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- I'm having an issue with the PlayStation. Please assist. Thank you.\n",
            "- I'm having an issue with the PlayStation. Please assist. Thank you.\n",
            "- I'm having an issue with I've recently updated the firmware of my PlayStation, and the issue started happening afterward. Could it be related to the update?\n",
            "- I'm having an issue with the Sony PlayStation. Please assist.\n",
            "- I'm having an issue with the PlayStation. Please assist. â€” Kevin\n"
          ]
        }
      ]
    }
  ]
}